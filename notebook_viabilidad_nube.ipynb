{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8519b-a24f-44df-9366-bdb405540bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importación de librerías principales ---\n",
    "\n",
    "# Manejo de datos tabulares y operaciones numéricas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Librería para generar números aleatorios (no esencial, pero útil para reproducibilidad o simulaciones)\n",
    "import random\n",
    "\n",
    "# --- Instalación y carga de librería financiera ---\n",
    "# numpy-financial se usa para cálculos financieros como TIR, VAN, etc.\n",
    "!pip install numpy-financial\n",
    "import numpy_financial as npf\n",
    "\n",
    "# --- Estadística ---\n",
    "# pearsonr permite calcular la correlación de Pearson (relación lineal entre dos variables)\n",
    "from scipy.stats import pearsonr\n",
    "import scipy.stats as stats\n",
    "\n",
    "# --- Deep Learning (TensorFlow / Keras) ---\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential   # Modelo secuencial (apilamiento de capas)\n",
    "from tensorflow.keras.layers import Dense         # Capa totalmente conectada (fully connected)\n",
    "from tensorflow.keras.optimizers import SGD       # Optimizador: descenso del gradiente estocástico\n",
    "\n",
    "# --- Métricas ---\n",
    "# confusion_matrix: matriz de confusión para evaluar la clasificación binaria\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4c8e0c-57bd-4f22-96f8-62cb6c975f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Carga y exploración inicial del conjunto de datos ---\n",
    "\n",
    "# Carga el archivo CSV en un DataFrame de pandas.\n",
    "# 'dataset.csv' debe encontrarse en el mismo directorio del notebook.\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Muestra el contenido completo del DataFrame (primeras filas por defecto en notebooks).\n",
    "df\n",
    "\n",
    "# Genera un resumen estadístico de las variables numéricas del dataset:\n",
    "# incluye media, desviación estándar, valores mínimo, máximo y percentiles (25%, 50%, 75%).\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d71ee1-7e5e-408b-a5b2-729b77acf8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Se extraen las columnas relevantes del DataFrame original y se convierten en arreglos de NumPy.\n",
    "# Cada arreglo representa una variable clave del proceso de desarrollo de software.\n",
    "datosDevs = df['Devs'].values\n",
    "datosSprint = df['Sprint'].values\n",
    "datosDiseno = df['Diseno'].values\n",
    "datosDesarrollo = df['Desarrollo'].values\n",
    "datosControl = df['Control'].values\n",
    "\n",
    "# Se realiza una copia profunda del DataFrame original para no modificar los datos base.\n",
    "df_copy = df.copy(deep=True)\n",
    "\n",
    "\n",
    "# --- Paso 3: Definición de parámetros para Bootstrapping ---\n",
    "\n",
    "n = len(datosDevs)           # Tamaño de la muestra original\n",
    "n_bootstrap = 2000           # Número de iteraciones Bootstrap (muestras con reemplazo)\n",
    "\n",
    "# Listas para almacenar los resultados generados durante las simulaciones\n",
    "medias_bootstrapDevs = []\n",
    "medias_bootstrapSprint = []\n",
    "medias_bootstrapDiseno = []\n",
    "medias_bootstrapDesarrollo = []\n",
    "medias_bootstrapControl = []\n",
    "\n",
    "\n",
    "# En cada iteración se seleccionan valores aleatorios (con reemplazo) de cada variable\n",
    "# y se calcula una nueva duración estimada (Duracion) combinando las fases del proyecto.\n",
    "for _ in range(n_bootstrap):\n",
    "\n",
    "    # Muestreo con reemplazo de cada variable\n",
    "    muestra_Devs = random.choice(datosDevs)\n",
    "    muestra_Sprint = random.choice(datosSprint)\n",
    "    muestra_Diseno = random.choice(datosDiseno)\n",
    "    muestra_Desarrollo = random.choice(datosDesarrollo)\n",
    "    muestra_Control = random.choice(datosControl)\n",
    "\n",
    "    # Cálculo de una nueva \"Duración\" simulada a partir de las variables seleccionadas\n",
    "    muestra_Duracion = (muestra_Diseno + muestra_Desarrollo + muestra_Control) * muestra_Sprint\n",
    "\n",
    "    # Se crea un nuevo registro (fila) con los valores simulados\n",
    "    new_row = pd.DataFrame({\n",
    "        'Devs': [muestra_Devs],\n",
    "        'Sprint': [muestra_Sprint],\n",
    "        'Diseno': [muestra_Diseno],\n",
    "        'Desarrollo': [muestra_Desarrollo],\n",
    "        'Control': [muestra_Control],\n",
    "        'Duracion': [muestra_Duracion]\n",
    "    })\n",
    "\n",
    "    # Se concatena la nueva fila al DataFrame copia\n",
    "    df_copy = pd.concat([df_copy, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Se calculan los percentiles 2.5 y 97.5 de las duraciones simuladas,\n",
    "# lo que representa un intervalo de confianza del 95% para la media de la variable Duracion.\n",
    "confianza_95 = np.percentile(df_copy['Duracion'].values, [2.5, 97.5])\n",
    "\n",
    "\n",
    "\n",
    "# Se construye un histograma para observar la distribución de las duraciones simuladas.\n",
    "plt.hist(df_copy['Duracion'].values, bins=50, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Se agregan líneas verticales que marcan los límites del intervalo de confianza.\n",
    "plt.axvline(confianza_95[0], color='red', linestyle='dashed', linewidth=2, label=f'2.5% Percentil: {confianza_95[0]:.2f}')\n",
    "plt.axvline(confianza_95[1], color='red', linestyle='dashed', linewidth=2, label=f'97.5% Percentil: {confianza_95[1]:.2f}')\n",
    "\n",
    "plt.title('Distribución de medias de las muestras Bootstrap')\n",
    "plt.xlabel('Media de Duración')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Se imprime el intervalo de confianza obtenido, el cual cuantifica la incertidumbre\n",
    "# asociada a la media estimada de la duración total de los proyectos simulados.\n",
    "print(f\"Intervalo de confianza del 95% para la media de Duracion: ({confianza_95[0]:.2f}, {confianza_95[1]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c28e6b7-e166-45f0-b197-b1a4078107e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Simulación de flujos y cálculo de TIR por fila (proyecto) ---\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Recorremos df_copy para construir los flujos semanales y calcular la TIR por proyecto simulado\n",
    "for index, row in df_copy.iterrows():\n",
    "    # Límite superior de filas procesadas (control de tiempo/recursos)\n",
    "    if index < 2013:\n",
    "        # --- Extracción de parámetros por fila ---\n",
    "        devs = row['Devs']           # número de desarrolladores\n",
    "        duracion = int(row['Duracion'])  # duración en sprints/semanas (asegurar entero)\n",
    "        \n",
    "        # --- Parámetros financieros (convención: negativos = egresos, positivos = ingresos) ---\n",
    "        costo_inicial = -53343.47    # inversión inicial \n",
    "        costo_fijo = -7089.26        # costo fijo por periodo \n",
    "        \n",
    "        # --- Flujo de caja semanal ---\n",
    "        # Se construye un vector: [flujo_0, flujo_1, ..., flujo_duracion]\n",
    "        flujo = []\n",
    "        flujo.append(costo_inicial)  # flujo en t=0\n",
    "        \n",
    "        # Nota: (devs*40*-125) = costo de horas hombre; (devs*40*175) = ingreso por horas facturadas\n",
    "        # En conjunto equivale a devs*40*(175-125)= devs*40*50, pero lo mantenemos explícito por claridad contable.\n",
    "        for i in range(duracion):\n",
    "            flujo_semanal = (devs * 40 * -125) + (devs * 40 * 175) + costo_fijo\n",
    "            flujo.append(flujo_semanal)\n",
    "        \n",
    "        # --- Cálculo de la TIR (npf.irr usa convención de signos del flujo) ---\n",
    "        tir = npf.irr(flujo)  # devuelve tasa en formato decimal (p.ej. 0.23 = 23%)\n",
    "        \n",
    "        # --- Construcción de la nueva fila con resultados ---\n",
    "        # IMPORTANTE: guardamos TIR numérica (float) para análisis estadístico posterior.\n",
    "        row['TIR'] = tir\n",
    "        row['Aceptado'] = \"SI\" if (tir * 100) > 20 else \"NO\"  # regla de decisión (hurdle rate 20%)\n",
    "        \n",
    "        # Se agrega la fila al DataFrame final\n",
    "        final_df = pd.concat([final_df, pd.DataFrame(row).T], ignore_index=True)\n",
    "\n",
    "# Vista rápida\n",
    "final_df\n",
    "\n",
    "# --- Persistencia a CSV y recarga (opcional para trazabilidad) ---\n",
    "final_df.to_csv('dataset_final.csv', index=False)\n",
    "final_df = pd.read_csv(\"dataset_final.csv\")\n",
    "\n",
    "# Resumen estadístico\n",
    "final_df\n",
    "final_df.describe()\n",
    "\n",
    "# --- Preparación para análisis de correlación ---\n",
    "# Removemos columnas no numéricas antes de correlación\n",
    "# (Si 'Aceptado' existe, la eliminamos; si 'TIR' se quiere excluir, se puede eliminar aquí)\n",
    "cols_a_eliminar = [c for c in ['TIR', 'Aceptado', 'TIR %'] if c in final_df.columns]\n",
    "final_df.drop(columns=cols_a_eliminar, inplace=True)\n",
    "\n",
    "# Matriz de correlación (solo numéricos)\n",
    "correlation_matrix = final_df.corr(numeric_only=True)\n",
    "\n",
    "# --- Función para matriz de p-values (correlaciones de Pearson) ---\n",
    "def calculate_pvalues(df_numeric):\n",
    "    # Asegurar solo columnas numéricas y sin NaN para evitar errores en pearsonr\n",
    "    df_numeric = df_numeric.select_dtypes(include=[np.number]).dropna()\n",
    "    p_values = pd.DataFrame(np.ones((df_numeric.shape[1], df_numeric.shape[1])),\n",
    "                            columns=df_numeric.columns, index=df_numeric.columns)\n",
    "\n",
    "    for i in range(len(df_numeric.columns)):\n",
    "        for j in range(i, len(df_numeric.columns)):\n",
    "            corr, p_value = pearsonr(df_numeric.iloc[:, i], df_numeric.iloc[:, j])\n",
    "            p_values.iloc[i, j] = p_value\n",
    "            p_values.iloc[j, i] = p_value\n",
    "\n",
    "    return p_values\n",
    "\n",
    "# Cálculo de p-values\n",
    "p_values_matrix = calculate_pvalues(final_df)\n",
    "\n",
    "# --- Visualizaciones ---\n",
    "\n",
    "# Mapa de calor de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Mapa de Calor de Correlación')\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor de p-values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(p_values_matrix, annot=True, cmap='Blues', vmin=0, vmax=1)\n",
    "plt.title('Mapa de Calor de P-values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbb6bf-3a4b-4c79-99ed-50bdcb4a486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtiene el intervalo de confianza del 95% para la variable 'Devs' (número de desarrolladores),\n",
    "# utilizando los percentiles 2.5 y 97.5 de la distribución empírica.\n",
    "confianza_95 = np.percentile(final_df['Devs'].values, [2.5, 97.5])\n",
    "\n",
    "# Se calcula la media de la distribución de desarrolladores.\n",
    "media = np.mean(final_df['Devs'].values)\n",
    "\n",
    "\n",
    "# ---  Visualización de la distribución de desarrolladores ---\n",
    "\n",
    "plt.hist(final_df['Devs'].values, bins=10, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Líneas verticales para marcar los percentiles (intervalo de confianza del 95%)\n",
    "plt.axvline(confianza_95[0], color='red', linestyle='dashed', linewidth=2, \n",
    "            label=f'2.5% Percentil: {confianza_95[0]:.2f}')\n",
    "plt.axvline(confianza_95[1], color='red', linestyle='dashed', linewidth=2, \n",
    "            label=f'97.5% Percentil: {confianza_95[1]:.2f}')\n",
    "\n",
    "# Línea verde sólida para la media\n",
    "plt.axvline(media, color='green', linestyle='solid', linewidth=3, \n",
    "            label=f'Media: {media:.2f}')\n",
    "\n",
    "# Títulos y etiquetas del gráfico\n",
    "plt.xlabel('Número de Desarrolladores (Devs)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---  Definición de la distribución triangular por columna numérica ---\n",
    "\n",
    "def triangle_distribution(df):\n",
    "    \"\"\"\n",
    "    Calcula los parámetros de la distribución triangular (mínimo, moda, máximo)\n",
    "    para cada columna numérica de un DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame de entrada.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame con los parámetros (min, mode, max) de cada variable numérica.\n",
    "    \"\"\"\n",
    "\n",
    "    # Selecciona solo las columnas numéricas del DataFrame\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    triangle_params = {}\n",
    "\n",
    "   # Itera por cada columna numérica y calcula los tres parámetros\n",
    "    for col in numeric_cols:\n",
    "        min_val = df[col].min()             # Valor mínimo\n",
    "        max_val = df[col].max()             # Valor máximo\n",
    "        mode_val = df[col].mode()[0]        # Moda (toma el primer valor si hay varias)\n",
    "        triangle_params[col] = {\n",
    "            'min': min_val,\n",
    "            'mode': mode_val,\n",
    "            'max': max_val\n",
    "        }\n",
    "\n",
    "    # Retorna los resultados en un DataFrame transpuesto (una fila por variable)\n",
    "    return pd.DataFrame(triangle_params).T\n",
    "\n",
    "\n",
    "triangle_df = triangle_distribution(final_df)\n",
    "triangle_df\n",
    "\n",
    "\n",
    "# Se genera una nueva columna binaria llamada 'Aceptado':\n",
    "# True si la TIR es mayor o igual al 20% (proyecto aceptado), False en caso contrario.\n",
    "final_df['Aceptado'] = final_df['TIR'] >= 20\n",
    "\n",
    "\n",
    "# Se agrupan los datos por 'Devs' (número de desarrolladores) y el estado de aceptación.\n",
    "resultado = final_df.groupby(['Devs', 'Aceptado'])['Devs'].count().unstack(fill_value=0)\n",
    "\n",
    "# Renombrar las columnas para mayor claridad en la tabla resultante\n",
    "resultado.columns = ['No Aceptados', 'Aceptados']\n",
    "\n",
    "# Mostrar la tabla resumen (frecuencia de aceptación por tamaño de equipo)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0304446-116e-464f-9f00-5c3aec14863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se carga nuevamente el dataset final con los resultados del cálculo de TIR\n",
    "final_df = pd.read_csv(\"dataset_final.csv\")\n",
    "\n",
    "# Se crea una copia de trabajo del DataFrame para manipularlo sin alterar el original\n",
    "model_df = final_df.copy()\n",
    "\n",
    "# --- Generación de la variable objetivo (target) ---\n",
    "\n",
    "# Se crea una nueva columna llamada 'Aceptar' que funcionará como variable de salida (Y) para la red neuronal.\n",
    "# La lógica aplicada es:\n",
    "#   Si la TIR > 20 → se etiqueta con 1 (proyecto aceptado)\n",
    "#   Si la TIR ≤ 20 → se etiqueta con 0 (proyecto no aceptado)\n",
    "# Este umbral del 20% actúa como la \"tasa mínima aceptable de retorno\" o *hurdle rate*.\n",
    "model_df[\"Aceptar\"] = [1 if x > 20 else 0 for x in model_df['TIR']]\n",
    "\n",
    "# --- Limpieza de variables no necesarias para el entrenamiento ---\n",
    "\n",
    "# Se eliminan las columnas que no deben incluirse como entradas del modelo:\n",
    "#  - 'TIR' y 'TIR %' → variables dependientes del resultado financiero\n",
    "#  - 'Aceptado' → etiqueta redundante con 'Aceptar'\n",
    "#  - 'Duracion' → puede eliminarse si no se utilizará como predictor\n",
    "model_df.drop(columns=['TIR', 'Aceptado', 'TIR %', 'Duracion'], inplace=True, errors='ignore')\n",
    "\n",
    "# --- Visualización del DataFrame final listo para el modelo ---\n",
    "# En este punto, model_df contiene exclusivamente variables independientes (X)\n",
    "# y la variable de salida binaria 'Aceptar' para el entrenamiento supervisado.\n",
    "model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d0874-b11d-4310-9e80-592642156002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Datos de ejemplo (X: características, y: etiquetas) ---\n",
    "\n",
    "# X: variables predictoras; y: etiqueta binaria (0/1) que indica si el proyecto se acepta\n",
    "X = model_df.drop(columns=['Aceptar'])   # Entrada (características)\n",
    "y = model_df['Aceptar']                  # Salida (etiquetas)\n",
    "\n",
    "# --- División 70/30 (opcional) ---\n",
    "# NOTA: el cliente pidió entrenar con 100% de los casos; por eso se deja comentado.\n",
    "#Inicialmente se utilizo este entrenamiento, despues del analisis de los resultados con el  cliente este preifirio utilizar el 100% de los datos\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# --- Definición del modelo (arquitectura 5–5–1) ---\n",
    "model = Sequential()\n",
    "\n",
    "# Capa oculta con 5 neuronas y 5 entradas (ReLU)\n",
    "model.add(Dense(5, input_dim=5, activation='relu'))\n",
    "\n",
    "# Capa de salida (1 neurona con Sigmoid para probabilidad de clase positiva)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilación del modelo: pérdida binaria, métrica de accuracy y optimizador SGD\n",
    "model.compile(optimizer=SGD(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- Entrenamiento ---\n",
    "# Entrena con el 100% de los datos (decisión del cliente). verbose=False para no saturar la salida.\n",
    "historial = model.fit(X, y, epochs=100, batch_size=1, verbose=False)\n",
    "\n",
    "# --- Evaluación (sobre el mismo set de entrenamiento) ---\n",
    "# Nota: medir en el mismo set tiende a sobreestimar el desempeño (optimismo).\n",
    "pérdida, precisión = model.evaluate(X, y, verbose=False)\n",
    "print(f\"Pérdida: {pérdida:.4f}\")\n",
    "print(f\"Precisión: {precisión:.4f}\")\n",
    "\n",
    "# --- Predicciones y umbral de decisión ---\n",
    "# Se obtienen probabilidades en [0,1] y se umbralizan a clase {0,1}.\n",
    "predicciones = model.predict(X, verbose=False)\n",
    "\n",
    "print(\"\\nProbabilidades / puntuaciones del modelo:\")\n",
    "print(predicciones.flatten())\n",
    "\n",
    "# Umbral de decisión elevado para priorizar alta certeza en positivos (minimizar falsos positivos)\n",
    "umbral = 0.90\n",
    "predicciones_binarias = (predicciones > umbral).astype(int)\n",
    "\n",
    "# --- Comparación con etiquetas reales ---\n",
    "print(\"\\nComparación con las etiquetas reales:\")\n",
    "print(f\"Predicciones binarias (umbral={umbral}): {predicciones_binarias.flatten()}\")\n",
    "print(f\"Etiquetas reales: {y.values}\")\n",
    "\n",
    "# --- Matriz de confusión ---\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, predicciones_binarias)\n",
    "\n",
    "print(\"\\nMatriz de confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# --- Curvas de entrenamiento (loss y accuracy) ---\n",
    "plt.plot(historial.history['loss'])\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(historial.history['accuracy'])\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión')\n",
    "plt.title('Precisión durante el entrenamiento')\n",
    "plt.show()\n",
    "\n",
    "# --- Heatmap de la matriz de confusión ---\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
    "            xticklabels=['Not Accepted', 'Accepted'],\n",
    "            yticklabels=['Not Accepted', 'Accepted'])\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual Results')\n",
    "plt.title('Matriz de Confusión')\n",
    "\n",
    "# Leyendas auxiliares (ubicación relativa al heatmap)\n",
    "plt.text(0.5, 1.05, 'FN: False Negatives', ha='center', va='center', fontsize=10, color='black', transform=plt.gca().transAxes)\n",
    "plt.text(0.88, 1.05, 'TP: True Positives', ha='center', va='center', fontsize=10, color='black', transform=plt.gca().transAxes)\n",
    "plt.text(0.5, -0.10, 'TN: True Negatives', ha='center', va='center', fontsize=10, color='black', transform=plt.gca().transAxes)\n",
    "plt.text(0.88, -0.10, 'FP: False Positives', ha='center', va='center', fontsize=10, color='black', transform=plt.gca().transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
